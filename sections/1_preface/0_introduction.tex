\chapter{Introduction}\label{chap:introduction}

\chapterQuote{\textit{``Ludwig Boltzman, who spent much of his life studying statistical mechanics, died in 1906, by his own hand. Paul Ehrenfest, carrying on the work, died similarly in 1933. Now it is our turn to study statistical mechanics.''}}{--- \textit{States of matter}, David L. Goodstein}

\chapterAbstract{T}{he purpose of this book is to present our work in Knowledge Graph reasoning. This chapter provides the required information for the reader to follow the topics discussed in this dissertation, it is structured in the following sections: 

Section~\ref{sec:intro-context}, contains; 
Section~\ref{sec:intro-rationale}, holds; 
Section~\ref{sec:intro-summary}, focuses on;
Section~\ref{sec:intro-collabs}, showcases,
Section~\ref{sec:intro-structure}, describes the structure of the rest of this book.}

\section{Research context}\label{sec:intro-context}

In recent years available information online has increased 60.000\%, from a modest 2 zettabytes ($10^{12}$ gigabytes) up to an estimate of 120 by the end of 2023\cite{}. The sheer volume of information generated on a daily basis calls for a structured and networked storage solution made possible by Knowledge Graphs, which rise to popularity was all but inevitable. These data structures hold information from multiple domains by using triples, two information nodes representing concepts connected by an edge representing a relationship between them, this relation can be either directional or linear. This form of representation gives them a graph-like structure containing a web of facts with a high degree of connectivity, offering complex reasoned chains of information in an effective way.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=\textwidth]{fig/intro/Gartner_2023.png}
    \caption{Gartner's 2023 hype chart for artificial intelligence.}
    \label{fig:garter-chart}
\end{figure}

The Garter institution situates Knowledge Graphs in the middle of their life cycle (cf. Figure \ref{fig:garter-chart}) meaning they can still benefit from active research and development and are still in their infancy in regards to their widespread applications in a multitude of fields. Some of the most notable fields and Knowledge Graphs corresponding to each of them are:
\begin{itemize}
    \item \textbf{Enciclopedic} KGs compile factual knowledge facts or events sourced from different domains, some examples are DBpedia\cite{auer2007dbpedia} which compiles the knowledge found in Wikipedia articles, Freebase\cite{bollacker2007freebase} which combines automatic processes from multiple sources as well as user contributions to wrangle up its data or YAGO\cite{suchanek2007yago} which adds a layer of complexity by adding temporal and geographical information to Wikipedia facts.
    \item \textbf{Linguistic} KGs compile facts about language and add a layer of information in the form of ontologies or external features on top, the most notable of these is WordNet\cite{miller1995wordnet} which provides hyponym and synonym relationships between words of the English language.
    \item \textbf{Enterprise} KGs support tech sector companies in their endeavors. The origin of Knowledge Graphs is found in this classification; the Google Knowledge Graph (GKG) \cite{steiner2012adding} boasting an impressive 800 billion facts on 8 billion entities. It compiles multi-domain information in order to rapidly respond to one of the many user queries made through their browser per day. 
    % Some other notable examples are Facebook's propietary KG, which holds information about its userbase's connections and likes in order to suggest new friends or groups.
\end{itemize}

Knowledge Graph construction is generally an automatic task since the large volume of data they hold is put off the range of human processing without it being an exceptionally arduous process, however, there are some notable exceptions such as the high-quality datasets that were constructed through crowdfunding efforts, Freebase\cite{bollacker2007freebase} and Wikidata\cite{vrandevcic2014wikidata}, automatic KG construction typically relies on semi-structured\cite{lehmann2015dbpedia} information ranging from XML type documents and html tables to plain text articles with a well-organized title structure.
Data Extraction from these sources has evolved over time from information extraction systems driven by designated rules or clustering \cite{yates2007textrunner, etzioni2004web}, to the current approaches such as, entity recognition\cite{huang2015bidirectional, ma2016end}, typing\cite{xu2018neural, ren2016label} and linking\cite{ganea2017deep, le2018improving} or relation extraction and curation\cite{zeng2015distant, zhou2016attention}. 

These methods of automated construction allow for a massive volume of data to be processed, however, they present several limitations.
First, the information they are built upon may be interpreted and linked erroneously or simply by being demonstrably wrong \cite{martinez2020information}, leading to incorrect facts being present in a KG. 
Second, Knowledge Graphs built from the same source might not be equal rendering them incompatible, they could represent the same facts with different nomenclature because they used a different schema to link that information \cite{choi2006survey}, meaning that joining Knowledge Graphs is never a trivial task.
Finally, Knowledge Graphs constructed in this manner will most likely be lacking information that was originally contained within the source material it used \cite{bordes2014constructing}. In addition, information sources generally do not include knowledge that the intended reader should already be aware of, in other words, no source will explicitly hold all information required for a single domain, therefore, Knowledge Graphs inherently lack triples that could otherwise exist in them.
Some techniques aim to fill this information gap in automatically constructed Knowledge Graphs, known as KG completion, and their focus is on finding links between existing entities that are not present in the KG but should be. However, KG completion efforts have a limitation shared by multiple binary classifiers in the literature, they generally provide an answer to a query that can be accompanied by a degree of confidence in the form of a percentage. This lack of explainability of their answers is a limitation in KG completion that KG reasoning aims to complement by providing reasoned paths to accompany their responses. In this way, a provided answer can be human-friendly as well as serve the same purpose in regards to KG completion.

Existing literature displays the multiple ways in which KG completion and reasoning have been tackled. Completion efforts can be separated into one of four existing categories\cite{shen2022comprehensive}, they are as follows.
\textbf{Semantic matching models}, compute a scoring function by measuring the semantic similarities of entity or relation embeddings in latent embedding space, they do so by applying \textbf{Neural Network} or \textbf{Tensor Factorization} models. 
NN models \cite{} present a challenging problem as they require the effective encoding of world knowledge using powerful models. However, research has shown that neural networks can capture the semantic features of entities and relations intelligently and model the semantic relationships between discrete entities, ultimately leading to more accurate embeddings of KGs.
Tensors\cite{} and their decompositions are widely used in data mining and machine learning problems. their usefulness comes from the representation they offer as KG entities and triples can be represented as tensors, KG completion can be tackled as a binary tensor completion problem\cite{shen2022comprehensive}.
\textbf{Translational models}\cite{} encode KG entities and relations as low-dimensional numerical vectors. a distance scoring function is then applied in the N-dimensional vectorial space reflecting the correctness of a proposed triple, then a ranking loss function is applied to learn the top translation relation between the entities in question.
\textbf{Structural models}\cite{} The inherent rich information inside KGs plays an important role in capturing useful features of knowledge embeddings for KG completion. the common internal information inside KGs includes node attribute information\cite{}, entity-related information\cite{}, relation-related information\cite{}, neighborhood information\cite{}, and relational path information\cite{}. This dissertation's proposal expands on relational path reasoning combined with translational elements as part of the contribution.

% this needs to be formalised, cited, completed and improved...
Obtaining information from relational paths contained within a KG is usually performed by applying machine learning algorithms; path capture\cite{}, path classification, path augmentation or multi-hop KG reasoning, all but the latter have a problem, they use a path ranking NN as a binary classifier which causes feature explosion for large KGs. In our work we chose to develop a multi-hop reasoning approach for this reason and for explainability of the decisions taken.
We also chose Reinforcement Learning to create intelligent agents tasked with solving this task. In practice this focuses on solving a stochastic gradient descent problem, that will be described in depth in future sections.
The RL agents traverse through the graph nodes as states by using connected relations as the action space.
Existing approaches that follow this methodology already exist, however, they generally apply rewards based in REINFORCE algorithm and blah blah blah...

% Machine Learning
% Reinforcement Learning as a solution,
% how Rl applies KG reasoning techniques


\section{Research rationale}\label{sec:intro-rationale}
In this section, we present the hypothesis that has motivated our research work in the context of Knowledge Graph reasoning and state our thesis, which we prove in the rest of the dissertation.

\subsection{Hypothesis}
% Nowadays, there is an increasing interest of individuals, organizations and companies in using Knowledge Graphs to represent information about a certain domain and to exploit said KGs to provide services. In the present day, practical applications such as question answering \cite{singhal2012}, product recommendations \cite{zhang2021, palumbo2020}, data retrieval \cite{wise2020} and meta-research \cite{dessi2022cskg,angioni2021} already rely on Knowledge Graphs. However, these applications need the data present in KGs to be as complete as possible, which makes it necessary to expand them after their creation.

% According to the previous argumentation, we conclude that our hypothesis is the following:

% \hypthesis{Knowledge Graphs provide value to individuals and companies alike by supporting applications that are widely used today, and their usefulness is likely to keep growing. Due to their incompleteness, there is a need to refine them and find the information that they are missing in order to expand them.} 

% ---------------------

% aqui es lo que asumo que es cierto de cara a presentar la tesis?
% existen X grafos que hacen cosas y conviene que esten completos porque ofrecen muchas cosas como QA, Recommendations Systems, Salud.
% es util poder responder a preguntas que se responden por la informacion no explicita de los mismos.
% se puede usar un sistema de reinforcement learning aprovechando la semantica interna de los mismos mendiante los embeddings


% asumiendo que es verdad

% porque esto es util.

\hypthesis{Hypothesis goes here.}

\subsection{Thesis}
% There already exist a number of techniques that can be applied to perform Knowledge Graph completion, e.g., \cite{jiang2016, galarraga2015, galarraga2013, wang2015, richardson2006, kuzelka2019, yang2017, sadeghian2019, minervini2018, wei2015, nickel2011, jenatton2012, garcia-duran2015, yang2014, tay2017, trouillon2016, bordes2013, wang2014, lin2015, do2018, lao2011, gardner2015, gardner2013, nastase2019, gu2015, toutanova2016, jiang2017, lei2019, bansal2019a2n, wang2019}. Unfortunately, they do not fulfill a number of requirements for their application to large Knowledge Graphs. Those that rely on extracting and applying rules suffer from a particularly poor scalability, which has been acknowledged in the literature \cite{galarraga2013}. A large number of proposals use latent representations such as tensors, or entity or relation embeddings. While they can be effective, they are hindered by the fact that these representations must be obtained beforehand, which is a very computationally intensive task, and they must be updated entirely when a new entity or relation is introduced to the graph, which is a frequent event. Furthermore, many other proposals for KG completion need to access external or manually-provided information, making them not fully automatic or self-contained.


% In light of the previous reasoning, we conclude that our thesis is as follows:

% \hypthesis{In the context of Knowledge Graph completion, it is possible to overcome the problems of existing proposals and develop a new one to automatically complete the missing information in a large KG, in a way that does not rely on external information or alternative representations, but that still achieves a high effectiveness.}


% las propuestas basadas en paths tienen tales pegas 

% teniendo en cuenta esto:

% nuestro paper mejora porque tal.

\hypthesis{thesis goes here.}


\section{Summary of contributions}\label{sec:intro-summary}
% codgio disponible en git, 
% propuesta en under review...

To prove our thesis, we have devised SpaceRL %a XXX YYY program that does stuff.:

% \begin{itemize}
%     \item \textbf{CHAI}, a technique that is able to quickly filter out a large amount of candidate triples, leaving only the most promising ones. To do this, CHAI generates a number of rules that determine which triples have a higher chance of representing correct facts and deserve further evaluation, and which ones are most likely wrong and should be discarded immediately. Each of these rules is generated in an iterative manner, evaluating which continuation for it is the most promising. After a rule has been expanded, it is assessed again to determine whether it needs to be expanded further or not.\\
    
%     Regarding this contribution, the article that describes it \cite{borrego2019} was accepted and presented at K-CAP 2019.\\

%     \item \textbf{CAFE}, a technique that is able to learn what constitutes a correct and a wrong fact, and thus can select only the correct triples provided by CHAI, which can then be added to a KG, completing it. CAFE relies upon a set of neighborhood-aware features that are able to accurately characterize the neighborhoods of a pair of entities. It then uses these features to transform all triples it is provided into feature vectors, and trains a set of neural classification models to learn to distinguish between correct and incorrect knowledge.\\
    
%     Regarding this contribution, the article that describes it \cite{borrego2021} was published in the EAAI journal.\\

%     \item \textbf{SciCheck}, a proposal that is specifically designed to complete scientific Knowledge Graphs. Due to the particularities of these KGs, regular KG completion proposals do not provide satisfactory results. SciCheck overcomes these issues by considering the semantic similarities of the research concepts in a KG and by leveraging the rich ontologies that such KGs usually have.\\
    
%     Regarding this contribution, the article that describes it \cite{borrego2022} was published in the IEEE Access journal.

% \end{itemize}

\section{Structure of this dissertation}\label{sec:intro-structure}
This dissertation is structured as follows:

\begin{description}
    \item[\textbf{Part I: Preface.}] 
    % It encompasses this introduction and Chapter \ref{chap:motivation}, in which we provide the motivation for our research work and we conclude that the existing proposals for automatically completing Knowledge Graphs have a number of drawbacks.\\
    
    \item[Part II: Background Information.] 
    % It provides information about Knowledge Graphs and the different proposals to complete them that can be found in the literature. In Chapter~\ref{chap:kgs}, we introduce the concept of Knowledge Graph, their main characteristics and the current open challenges regarding them. In Chapter~\ref{chap:embeddings}, we present different proposals to complete KGs that rely on latent triple representations. In Chapter~\ref{chap:paths}, we provide an overview of the KG completion proposals that use information found in paths between entities and, in Chapter~\ref{chap:rules}, we summarize the existing proposals to perform this task using logical rules.\\
    
    \item[Part III: Our Proposal.]
    % It reports on the main contribution of this dissertation. In Chapter~\ref{chap:framework}, we define a common framework of definitions and concepts. In Chapter~\ref{chap:chai}, we present our proposal for automated candidate triple filtering, which is able to quickly discard a large number of incorrect triples. In Chapter~\ref{chap:cafe}, we describe our proposal for triple classification, which can assess the correctness of a triple with a high efficacy. Finally, in Chapter~\ref{chap:scicheck}, we present our technique for completing scientific Knowledge Graphs, along with a practical use case.\\
    
    \item[Part IV: Final Remarks.]
    % It contains Chapter~\ref{chap:conclusions}, which concludes this dissertation and presents some possible future research directions.
\end{description}