\chapter{Motivation}\label{chap:motivation}

\chapterQuote{\textit{``The worthwhile problems are the ones you can really solve or help solve, the ones you can really contribute something to. No problem is too small or too trivial if we can really do something about it.''}}{--- Richard Feynman}

\chapterAbstract{K}{nowledge Graph reasoning using reinforcement learning is an active topic of research, several proposals have emerged in recent years, however, they present drawbacks that hinder them. This chapter studies these proposals the problems each of them presents, and how that motivated our work. This chapter is organized as follows: Section~\ref{sec:moti-intro} introduces it and provides the necessary background knowledge, Section~\ref{sec:moti-problems} presents the problems that show up in KG reasoning, Section~\ref{sec:moti-analysis} analyzes the current approaches and their drawbacks, Section~\ref{sec:moti-discussion} explains how none of the existing proposals solves all practical problems at a time, Section~\ref{sec:moti-proposal} introduces our contributions and compares them with the existing proposals in the literature; finally, Section~\ref{sec:moti-summary} summarizes the chapter.}

\section{Introduction}\label{sec:moti-intro}
In recent years, there has been a growing interest of major tech companies in Knowledge Graphs (KGs) fueled by the proven efficacy of KGs in structuring and organizing information. Giants like Google, Facebook, and Microsoft adopted KGs as part of the core of their organizations, recognizing them as instrumental in organizing vast amounts of information, a new era of knowledge representation unfolds. This chapter explores the motivations driving the creation of this book, tracing the trajectory of the growing significance of KGs in information management.

Knowledge Graphs, with their inherent ability to capture complex relationships between entities, have proven to be indispensable tools for organizing information at an unprecedented scale. The capacity to structure data in a way that reflects the intricacies of real-world connections, offering a more nuanced understanding of the underlying domain.

However, the way in which KGs are automatically constructed leads to their inherent incompleteness, hence the main challenge for KGs lies in their augmentation with unexplicited information that can be inferred from itself, the process of Knowledge Graph Completion (KGC), in this way ensuring they are as comprehensive as possible.

KGC provides new knowledge to be incorporated into the KG, it provides no reason for it more than a numerical value, KG reasoning stands as a pivotal advancement in this matter. Unlike conventional completion approaches that primarily address missing links through direct imputation, KG reasoning introduces a more sophisticated layer of inference.

Through reasoning, the completion process transcends mere data imputation, dynamically synthesizing implicit connections within the graph, offering a more nuanced and comprehensive representation of the underlying knowledge, by leveraging Reinforcement Learning it is possible to generate intelligent agents capable of constructing paths of reasoned knowledge that offer insight into the facts being inserted into the graph.

In the literature, there are different proposals that address the problem of applying KG reasoning through RL for Knowledge graphs, e.g., \cite{}. These proposals, however, are limited due to the application of the methods they propose. For this reason, furthering the strategies and methodologies for KG reasoning is our main purpose in this dissertation.

\section{Problems}\label{sec:moti-problems}
Knowledge graph completion is a complex task, more so if we focus on explaining the knowledge being generated. Obtaining said knowledge through reinforcement learning algorithms presents its own set of challenges to add to that, and to be successful in practice, these challenges must be overcome. In this section, we present some of the problems that appear in the proposals focusing on this topic:

\begin{description}
    \item[(P1) Usage of embedding representations while not providing them:]
    Multiple proposals that tackle the problem of Knowledge Graph reasoning require being provided with the embedded representation of entities and relations on the graph, this forces users to generate these representations which can be a deterrent to the accessibility of the tools created. 
    Embedded representations work by capturing meaningful semantic similarities among diverse elements of the graph and compacting them into a numerical N-dimensional vector; however, they are accompanied by a significant drawback, they are highly sensitive to alterations on the KG and must be re-generated if any change occurs to said KG.
    Using these embedded representations is a double-edged sword, it allows for a simple way to vectorize graph elements, but, it makes the proposals using them dependent on them and in general, they do not offer a way to generate them on the fly, adding another layer of complexity to the process.\\
    
    \item[(P2) Hardcoded implementations of specific approaches or no implementation at all:] Existing KGC and KGR approaches focus only on generating data for publication purposes, this entails that the tools produced are not practical for usage outside of that scope, if they are even available, which is not always the case, they generally lack customizability, they require the embedding representation to be provided and they are cumbersome to expand or update. This reduces accessibility to these tools to users who seek further development in the field, users who want to make use of the tools but lack the required expertise to make them work, or users who want to expand them for their purposes.\\
    
    \item[(P3) Knowledge graph completion offers low explainability of solutions provided:] One of the main problems with KGC which is intrinsic to the nature of the technique is the nonexistent explainability of the knowledge generated. KGC techniques generally fall under the umbrella of binary classifiers, they offer a simple yes or no answer to a query triple and it's then incorporated into the graph. Embedding techniques also offer a ranking of triples that fit a given query (h, r, ?) but also offer no reason behind them.\\ 
    
    \item[(P4) Reward structured based on terminality:] Reasoning techniques attempt to teach a Reinforcement Learning agent to traverse graph nodes as states and relations as the possible actions. The training of this agent has been performed in a variation of a particular approach throughout the literature, the agent must reach the target node and the rewards are retropropagated through the graph nodes visited. This requirement of reaching the end node before the policy network can begin to be modified causes high inference times \\
    
    \item[(P5) KGR techniques use low convergence algorithms:] There exists a plethora of Reinforcement Learning algorithms, due to the nature of the reward structure (a binary reward upon reaching the destination node) it is a forced choice to use a retropropagation algorithm. These algorithms have a major drawback of having a low convergence rate for complex problems, in theory, if left ad-infinitum it would always converge on the correct solution, however, this is obviously impractical in a real-world scenario. Retropropagated algorithms tend to get stuck in local optimums as they have no awareness of the optimal path beforehand or have no metric to follow apart from the fact that they have successfully reached the state they were required to or not.
\end{description}

\section{Analysis of current solutions}\label{sec:moti-analysis}

A number of proposals that work on Knowledge Graph Reasoning already exist in the literature. Table~\ref{table:proposals}, displays the most relevant ones which will be discussed in the following parragraphs in further detail

\input{tables/motivation/proposals}

\citet{lao2011random} presented the Path Ranking Algorithm, it obtains reasoned paths connecting entities and ranks them based on a multitude of random walks performed over the knowledge graph and then tunes the weights in future random walks according to the result of previous inference.

\citet{nickel2011three} devised RESCAL as a way to represent knowledge graphs by modeling the triples as tensors, where two modes of the tensor represented the entities and another mode the relation that connects them. By organizing the Graph in this way it can perform tensor factorization operations and predict the existence of triples by observing the rank-reduced reconstruction of the produced slice.

\citet{bordes2013translating} proposes a method to embed entities from a Knowledge Graph into an N-dimensional space, aligning semantical similarities with physical distance in this space. The approach involves learning embeddings that enable a meaningful arrangement of entities based on their semantic attributes. Notably, the method introduces a novel criterion for triple accuracy, evaluating it by analyzing the relative positions of entities in the embedded space, and linking semantic coherence with geometric proximity.

\citet{wang2014knowledge} improved upon this previous method by altering the way in which the position of the ranked relations was calculated, instead of linearly they performed a translation into a hyperplane based on the vector of the evaluated triple's relation in the N-dimensional space, this paved the way for many other models which improved upon these ideas.

\citet{xiong2017deeppath} presented DeepPath, where pre-computed paths are evaluated by several metrics by a reinforcement learning algorithm, and ranked based on these metrics.

\citet{das2017go} proposed MINERVA, a proposal on KG reasoning based on reinforcement learning, this proposal opened a path for others to follow, it was the first to propose the usage of graphs nodes as states, and relations as possible actions, they implemented it based on a simple terminal reward that retropropagated to the previous states following the REINFORCE implementation.

\citet{lin2018multi} implemented a multi-hop KGR proposal, this technique was the first to take on improving the reward structure presented by MINERVA, it reinforced the reward by comparing it to a pre-trained one-hop model which helped estimate the reward of evaluated facts and introduced the concept of action masking to force the agent to take paths that might not normally be explored.

\citet{xian2019reinforcement} proposed an implementation that focuses on Recommendation systems via a method called PGPR which focuses on providing interpreted paths, relying also on a terminal reward complemented by a secondary NN that helps the inference during training in a dual manner.

\citet{vashishth2020interacte} devised InteractE a proposal that also relies on dimensionalizing graph elements, then applying convolutional neural networks to them in order to perform operations on the features of these embedded representations instead of a translation operation for them to interact more (hence the name) causing a more rich solution for the destination node.

\citet{tiwari2021dapath} presented a distance-aware reward system that addresses variable rewards at different graph positions by integrating graph self-attention mechanisms to capture entity information and combine it with a (GRU) for path retention.

\citet{cui2023incorporating} constructed an approach that focuses on anticipating the next step of the agent being trained with an "anticipation network", It treats the queries as a question and searches for an answer, using reward shaping and SAC.

\section{Challenges}\label{sec:moti-discussion}
% \todo{add citations to this section of problems.}

The proposals presented in the previous sections all have one or multiple drawbacks.

Regarding the usage of embeddings (P1), most if not all proposals based on reinforcement learning rely on these representations to operate, making them suffer from the problems that accompany them, moreover, they do not provide the user with a simple way to generate these embedded models further hindering their usability. Proposals that try to perform KG completion by leveraging translational models or variations of them also require these embeddings to be generated as it is the core of these proposals, this makes their results less interpretable.

Most of, if not all, proposals regarding the topics of KGC and KGR ignore the usability and expandability of their work (P2), they focus on presenting their implementations in a simple manner so that their results are replicable in a few command line prompts, however, this is not useful for researchers looking to further a topic or users trying to apply these works to some applications.

KGC approaches \cite{nickel2011three, bordes2013translating, wang2014knowledge,vashishth2020interacte} all are hindered by the lack of reason behind their approaches (P3), they compute either a ranking or classify a list of given triples but lack the capacity to offer a sense of the results they provide, for this reason, results given are unverifiable by humans that are not experts on the domain being treated and will have to be trusted blindly.

But explainability is not everything, if approaches that do offer reason to the answers provided are bound to the same lacking methodology (P5) when obtaining it, they can become hard to train and get stuck in local optimums if the precise expected configurations are not attained by the users who try and make use of them, several proposals \cite{}, suffer from this and would benefit from leveraging more modern algorithms that prevent these local optimums from forming in the Policy NN.

In tandem with this problem is also the fact that the majority of proposals focus on altering how the policy learns and reacts by tweaking the same base terminal reward (P4). These policies provoke spurious paths to occur and several \cite{} try to mitigate with a plethora of solutions, masking actions, following pre-trained one-hop models to compare to for each of the actions, when a generalistic guided reward can avoid most of these problems while also leveraging terminality.

\section{Our proposal}\label{sec:moti-proposal}
In order to mitigate the aforementioned problems, we present SpaceRL, our Knowledge Graph Reasoning framework, and end-to-end tool which provided a dataset outputs trained models able to perform KG reasoning on said KG (P3).

SpaceRL implements a novel, fundamentally different set of reward functions that exploit node embeddings, as well as the structural distance to the answer node, we reward actions that lead to nodes that are semantically similar to the target or are closer to it, without having to reach the answer node (P4). We also evaluate for the first time the application of the Proximal Policy Optimization (PPO) and Soft Actor Critic (SAC) (P5)

SpaceRL combines the benefits from RL pathfinding with the power of representational embeddings to infer fairly long and explainable paths, useful for KG-based applications, and it can do so with on-the-fly embedding generation, which means that the KG embeddings are not a required input to the system (P1).

Our tool is highly configurable, allowing for reward calculation to be modified with a combination of several options while allowing the user to apply state-of-the-art RL algorithms out of the box (P2), namely Proximal Policy Optimization (PPO)\cite{schulman2017proximal} combined with Soft Actor-Critic (SAC)\cite{haarnoja2018soft}, which improve performance and help avoid reward plateaus while training.

Finally, SpaceRL aims to provide a versatile tool intended for users with different levels of expertise, from novices to experts. It allows comprehensive and flexible customization for advanced users, who may prefer to install SpaceRL as a server for their local usage or to become a service provider for third parties.

SpaceRL offers RL model generation and usage as a service capability, either locally through its GUI or as a deployable REST API for third-party consumption. 

\section{Summary}\label{sec:moti-summary}
In this chapter, we have elaborated on the motivation for this dissertation. We analyzed the problems present in Knowledge Graphs Reasoning and Completion and the current proposals that exist in the literature and concluded that none of these proposals solve all of these problems.