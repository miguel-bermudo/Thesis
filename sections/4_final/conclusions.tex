\chapter{Conclusions}\label{chap:conclusions}

% guarrada para que las dos líneas queden más o menos alineadas sin contar las comillas, sorry
\chapterQuote{\hfill\textit{``Be proud: you've come such a long way.\,\,\,\,\,\,\\\null\hfill Be careful: there is so much further to go.''}}{--- \textit{Letter to Marble 3}, Exurb1a}

\vspace{1cm}

\noindent In this dissertation, we have presented a proposal to automatically complete large Knowledge Graphs. Our proposal takes as input the KG itself, and outputs a set of facts that it is missing and can be added back to it, enriching the graph with new knowledge. To achieve this, our proposal relies on a series of subsystems that address different problems of completing KGs.

First, it generates a set of candidate triples using CHAI, a technique that is able to efficiently generate rules to filter out incorrect knowledge. These rules combine aspects such as the distance between the entities of a triple, the domain and range restrictions of the relations in the KG, and the previous appearances of similar triples. Thanks to CHAI, our proposal is able to generate most of the missing facts in a KG while immediately discarding a large volume of incorrect knowledge.

Then, the candidate triples are evaluated using CAFE, our triple classification technique. CAFE defines a number of neighborhood-aware features that are able to accurately characterize the neighborhood of an entity, as well as the similarities between the neighborhoods of a pair of entities. These features are used to transform all triples in a KG, as well as possible candidate triples, into numeric vectors. CAFE then trains deep neural classification models using these vectors, learning to differentiate between correct and incorrect triples.

Both CAFE and CHAI have been evaluated using some of the most well-known Knowledge Graphs available today, and their theoretical performance has been shown to be efficient and effective. However, to demonstrate the applicability in practice of our proposal, we have introduced SciCheck, a technique for completing scientific Knowledge Graphs that builds upon the previously discussed ones, extending them with capabilities specifically tailored for these KGs. We have applied SciCheck to AI-KG, a large-scale KG that contains more than 14 million triples representing 1.2 million statements about scientific facts regarding the Artificial Intelligence domain. This resulted in more than 300K additional facts being generated by SciCheck since they were missing in AI-KG, which were later included in a subsequent update of this graph.

As future work, we think that some shortcomings of the current proposals for KG completion deserve more attention: most of the existing proposals in the literature focus only on single-modal KGs, and they do not address the fact that many multi-modal and multi-media KGs currently exist and are still incomplete; more research should be carried out in the field of efficiently generating candidate triples, since there is still a very small body of work in this regard; and an emphasis should be put on developing methods with a high explainability that can scale up to very large KGs, since this is still an area of active research. Additionally, it would be interesting to further analyze the possibility of completing Knowledge Graphs using less studied or recently proposed approaches, such as reinforcement learning or graph neural networks.